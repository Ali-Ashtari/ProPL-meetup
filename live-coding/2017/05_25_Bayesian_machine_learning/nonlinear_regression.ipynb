{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, Normalize\n",
    "from tempfile import NamedTemporaryFile\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "sns.set_context(\"talk\", font_scale=1.4)\n",
    "sess = ed.get_session()\n",
    "\n",
    "sns.palplot(sns.color_palette())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this can be done only before using Edward\n",
    "ed.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Nonlinear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from edward.models import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA\n",
    "N = 1000  # number of training data points\n",
    "Np = 100  # number of test data points\n",
    "D = 1  # number of features\n",
    "\n",
    "weights_true = sess.run(Normal(loc=tf.ones(D) * 1.25,\n",
    "                               scale=tf.ones(D) * 0.1))  # unknown true weights\n",
    "intercept_true = sess.run(Normal(loc=tf.zeros(1),\n",
    "                                 scale=tf.ones(1)))  # unknown true intercept\n",
    "noise_true = 0.1  # unknown true amount of noise\n",
    "\n",
    "def target_function(x):\n",
    "    return tf.sin(tf.square(ed.dot(x, weights_true))) + intercept_true\n",
    "\n",
    "def build_dataset(N):\n",
    "    x = Normal(loc=tf.zeros([N, D]), scale=tf.ones([N, D]))\n",
    "    y = Normal(loc=target_function(x), scale=noise_true)\n",
    "    return sess.run([x, y])\n",
    "\n",
    "x_train, y_train = build_dataset(N)\n",
    "x_test, y_test = build_dataset(Np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train, s=20.0);\n",
    "plt.scatter(x_test, y_test, s=20.0,\n",
    "            color=sns.color_palette().as_hex()[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MODEL A\n",
    "def neural_network_with_2_layers(x, W_0, W_1, b_0, b_1):\n",
    "    h = tf.nn.tanh(tf.matmul(x, W_0) + b_0)\n",
    "    h = tf.matmul(h, W_1) + b_1\n",
    "    return tf.reshape(h, [-1])\n",
    "\n",
    "dim = 10  # layer dimensions\n",
    "\n",
    "W_0 = Normal(loc=tf.zeros([D, dim]),\n",
    "             scale=tf.ones([D, dim]))\n",
    "W_1 = Normal(loc=tf.zeros([dim, 1]),\n",
    "             scale=tf.ones([dim, 1]))\n",
    "b_0 = Normal(loc=tf.zeros(dim),\n",
    "             scale=tf.ones(dim))\n",
    "b_1 = Normal(loc=tf.zeros(1),\n",
    "             scale=tf.ones(1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, [N, D])\n",
    "y = Normal(loc=neural_network_with_2_layers(x, W_0, W_1, b_0, b_1),\n",
    "           scale=tf.ones(N) * 0.1)  # constant noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BACKWARD MODEL A\n",
    "q_W_0 = Normal(loc=tf.Variable(tf.random_normal([D, dim])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([D, dim]))))\n",
    "q_W_1 = Normal(loc=tf.Variable(tf.random_normal([dim, 1])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([dim, 1]))))\n",
    "q_b_0 = Normal(loc=tf.Variable(tf.random_normal([dim])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([dim]))))\n",
    "q_b_1 = Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE A\n",
    "# this will take a couple of minutes\n",
    "inference = ed.KLqp(latent_vars={W_0: q_W_0, b_0: q_b_0,\n",
    "                                 W_1: q_W_1, b_1: q_b_1},\n",
    "                    data={x: x_train, y: y_train})\n",
    "inference.run(n_samples=10, n_iter=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICISM A\n",
    "plt.scatter(x_train, y_train, s=20.0);  # blue\n",
    "plt.scatter(x_test, y_test, s=20.0,  # red\n",
    "            color=sns.color_palette().as_hex()[2]);\n",
    "\n",
    "xp = tf.placeholder(tf.float32, [1000, D])\n",
    "[plt.plot(np.linspace(-4.0, 4.0, 1000),\n",
    "          sess.run(neural_network_with_2_layers(xp,\n",
    "                                                q_W_0, q_W_1,\n",
    "                                                q_b_0, q_b_1),\n",
    "                   {xp: np.linspace(-4.0, 4.0, 1000)[:, np.newaxis]}),\n",
    "          color='black', alpha=0.1)\n",
    " for _ in range(50)];\n",
    "\n",
    "plt.plot(np.linspace(-4.0, 4.0, 1000),\n",
    "         sess.run(target_function(xp),  # blue\n",
    "                  {xp: np.linspace(-4.0, 4.0, 1000)[:, np.newaxis]}));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp = tf.placeholder(tf.float32, [Np, D])\n",
    "y_post = Normal(loc=neural_network_with_2_layers(xp,\n",
    "                                                 q_W_0, q_W_1,\n",
    "                                                 q_b_0, q_b_1),\n",
    "                scale=tf.ones(Np) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error on test data:\")\n",
    "print(ed.evaluate('mean_squared_error', data={xp: x_test, y_post: y_test}))\n",
    "\n",
    "print(\"Mean absolute error on test data:\")\n",
    "print(ed.evaluate('mean_absolute_error', data={xp: x_test, y_post: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MODEL B\n",
    "def neural_network_with_3_layers(x, W_0, W_1, W_2, b_0, b_1, b_2):\n",
    "    h = tf.tanh(tf.matmul(x, W_0) + b_0)\n",
    "    h = tf.tanh(tf.matmul(h, W_1) + b_1)\n",
    "    h = tf.matmul(h, W_2) + b_2\n",
    "    return tf.reshape(h, [-1])\n",
    "\n",
    "dim = 10  # layer dimensions\n",
    "\n",
    "W_0 = Normal(loc=tf.zeros([D, dim]),\n",
    "             scale=tf.ones([D, dim]))\n",
    "W_1 = Normal(loc=tf.zeros([dim, dim]),\n",
    "             scale=tf.ones([dim, dim]))\n",
    "W_2 = Normal(loc=tf.zeros([dim, 1]),\n",
    "             scale=tf.ones([dim, 1]))\n",
    "b_0 = Normal(loc=tf.zeros(dim),\n",
    "             scale=tf.ones(dim))\n",
    "b_1 = Normal(loc=tf.zeros(dim),\n",
    "             scale=tf.ones(dim))\n",
    "b_2 = Normal(loc=tf.zeros(1),\n",
    "             scale=tf.ones(1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, [N, D])\n",
    "y = Normal(loc=neural_network_with_3_layers(x, W_0, W_1, W_2, b_0, b_1, b_2),\n",
    "           scale=tf.ones(N) * 0.1)  # constant noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BACKWARD MODEL B\n",
    "q_W_0 = Normal(loc=tf.Variable(tf.random_normal([D, dim])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([D, dim]))))\n",
    "q_W_1 = Normal(loc=tf.Variable(tf.random_normal([dim, dim])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([dim, dim]))))\n",
    "q_W_2 = Normal(loc=tf.Variable(tf.random_normal([dim, 1])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([dim, 1]))))\n",
    "q_b_0 = Normal(loc=tf.Variable(tf.random_normal([dim])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([dim]))))\n",
    "q_b_1 = Normal(loc=tf.Variable(tf.random_normal([dim])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([dim]))))\n",
    "q_b_2 = Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INFERENCE B\n",
    "# this will take ten minutes or longer\n",
    "inference = ed.KLqp(latent_vars={W_0: q_W_0, b_0: q_b_0,\n",
    "                                 W_1: q_W_1, b_1: q_b_1,\n",
    "                                 W_2: q_W_2, b_2: q_b_2},\n",
    "                    data={x: x_train, y: y_train})\n",
    "inference.run(n_samples=10, n_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CRITICISM B\n",
    "plt.scatter(x_train, y_train, s=20.0);  # blue\n",
    "plt.scatter(x_test, y_test, s=20.0,  # red\n",
    "            color=sns.color_palette().as_hex()[2]);\n",
    "\n",
    "xp = tf.placeholder(tf.float32, [1000, D])\n",
    "[plt.plot(np.linspace(-4.0, 4.0, 1000),\n",
    "          sess.run(neural_network_with_3_layers(xp,\n",
    "                                                q_W_0, q_W_1, q_W_2,\n",
    "                                                q_b_0, q_b_1, q_b_2),\n",
    "                   {xp: np.linspace(-4.0, 4.0, 1000)[:, np.newaxis]}),\n",
    "          color='black', alpha=0.1)\n",
    " for _ in range(50)];\n",
    "\n",
    "plt.plot(np.linspace(-4.0, 4.0, 1000),\n",
    "         sess.run(target_function(xp),  # blue\n",
    "                  {xp: np.linspace(-4.0, 4.0, 1000)[:, np.newaxis]}));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp = tf.placeholder(tf.float32, [Np, D])\n",
    "y_post = Normal(loc=neural_network_with_3_layers(xp,\n",
    "                                                 q_W_0, q_W_1, q_W_2,\n",
    "                                                 q_b_0, q_b_1, q_b_2),\n",
    "                scale=tf.ones(Np) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Mean squared error on test data:\")\n",
    "print(ed.evaluate('mean_squared_error', data={xp: x_test, y_post: y_test}))\n",
    "\n",
    "print(\"Mean absolute error on test data:\")\n",
    "print(ed.evaluate('mean_absolute_error', data={xp: x_test, y_post: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (PyCon)",
   "language": "python",
   "name": "python2_pycon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
