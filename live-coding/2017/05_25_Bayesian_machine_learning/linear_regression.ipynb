{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, Normalize\n",
    "from tempfile import NamedTemporaryFile\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "sns.set_context(\"talk\", font_scale=1.4)\n",
    "sess = ed.get_session()\n",
    "\n",
    "sns.palplot(sns.color_palette())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this can be done only before using Edward\n",
    "ed.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from edward.models import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(-5.0, 5.0, 0.001)\n",
    "plt.plot(*sess.run([x, Normal(loc=tf.ones(1) * 0.0,                # blue\n",
    "                              scale=tf.ones(1) * 1.0).prob(x)]));\n",
    "plt.plot(*sess.run([x, Normal(loc=tf.ones(1) * 2.0,                # green\n",
    "                              scale=tf.ones(1) * 1.0).prob(x)]));\n",
    "plt.plot(*sess.run([x, Normal(loc=tf.ones(1) * 0.0,                # red\n",
    "                              scale=tf.ones(1) * 2.0).prob(x)]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA\n",
    "N1 = 10  # number of training data points in first batch\n",
    "N2 = 90  # number of training data points in second batch\n",
    "Np = 10  # number of test data points\n",
    "D = 1  # number of features\n",
    "\n",
    "weights_true = sess.run(Normal(loc=tf.ones(D) * 2.0,\n",
    "                               scale=tf.ones(D) * 0.1))  # unknown true weights\n",
    "intercept_true = sess.run(Normal(loc=tf.zeros(1),\n",
    "                                 scale=tf.ones(1)))  # unknown true intercept\n",
    "noise_true = 0.35  # unknown true amount of noise\n",
    "\n",
    "def build_dataset(N):\n",
    "    x = Normal(loc=tf.zeros([N, D]), scale=tf.ones([N, D]))\n",
    "    y = Normal(loc=ed.dot(x, weights_true) + intercept_true, scale=noise_true)\n",
    "    return sess.run([x, y])\n",
    "\n",
    "x_train1, y_train1 = build_dataset(N1)\n",
    "x_train2, y_train2 = build_dataset(N2)\n",
    "x_test, y_test = build_dataset(Np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train1, y_train1, s=20.0);  # blue\n",
    "# plt.scatter(x_train2, y_train2, s=20.0);  # green\n",
    "plt.scatter(x_test, y_test, s=20.0,\n",
    "            color=sns.color_palette().as_hex()[2]);  # red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Little Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from edward.models import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FORWARD MODEL\n",
    "x = tf.placeholder(tf.float32, [N1, D])\n",
    "weights = Normal(loc=tf.zeros(D), scale=tf.ones(D))\n",
    "intercept = Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "y = Normal(loc=ed.dot(x, weights) + intercept,\n",
    "           scale=tf.ones(N1) * 0.01)  # with little noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BACKWARD MODEL\n",
    "q_weights = Normal(loc=tf.Variable(tf.random_normal([D])),\n",
    "                   scale=tf.nn.softplus(tf.Variable(tf.random_normal([D]))))\n",
    "q_intercept = Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "                     scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE\n",
    "inference = ed.KLqp(latent_vars={weights: q_weights,\n",
    "                                 intercept: q_intercept},\n",
    "                    data={x: x_train1,\n",
    "                          y: y_train1})\n",
    "inference.run(n_samples=50, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICISM\n",
    "plt.scatter(x_train1, y_train1, s=20.0);  # blue\n",
    "plt.scatter(x_test, y_test, s=20.0,\n",
    "            color=sns.color_palette().as_hex()[2]);  # red\n",
    "\n",
    "xp = tf.placeholder(tf.float32, [2, D])\n",
    "[plt.plot(np.linspace(-4.0, 4.0, 2),\n",
    "          sess.run(ed.dot(xp, q_weights) + q_intercept,\n",
    "                   {xp: np.linspace(-4.0, 4.0, 2)[:, np.newaxis]}),\n",
    "          color='black', alpha=0.1)\n",
    " for _ in range(50)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_post = ed.copy(y, {weights: q_weights,\n",
    "                     intercept: q_intercept})\n",
    "# this is equivalent to\n",
    "# y_post = Normal(loc=ed.dot(x, q_weights) + q_intercept,\n",
    "#                 scale=tf.ones(N1) * 0.01)\n",
    "# ed.copy works for us only because Np=N1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error on test data:\")\n",
    "print(ed.evaluate('mean_squared_error', data={x: x_test, y_post: y_test}))\n",
    "\n",
    "print(\"Mean absolute error on test data:\")\n",
    "print(ed.evaluate('mean_absolute_error', data={x: x_test, y_post: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# that's not bad, but the model is way too overconfident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FORWARD MODEL\n",
    "x = tf.placeholder(tf.float32, [N1, D])\n",
    "weights = Normal(loc=tf.zeros(D), scale=tf.ones(D))\n",
    "intercept = Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "y = Normal(loc=ed.dot(x, weights) + intercept,\n",
    "           scale=tf.ones(N1))  # with more noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BACKWARD MODEL\n",
    "q_weights = Normal(loc=tf.Variable(tf.random_normal([D])),\n",
    "                   scale=tf.nn.softplus(tf.Variable(tf.random_normal([D]))))\n",
    "q_intercept = Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "                     scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE\n",
    "inference = ed.KLqp(latent_vars={weights: q_weights,\n",
    "                                 intercept: q_intercept},\n",
    "                    data={x: x_train1,\n",
    "                          y: y_train1})\n",
    "inference.run(n_samples=50, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICISM\n",
    "plt.scatter(x_train1, y_train1, s=20.0);  # blue\n",
    "plt.scatter(x_test, y_test, s=20.0,\n",
    "            color=sns.color_palette().as_hex()[2]);  # red\n",
    "\n",
    "xp = tf.placeholder(tf.float32, [2, D])\n",
    "[plt.plot(np.linspace(-4.0, 4.0, 2),\n",
    "          sess.run(ed.dot(xp, q_weights) + q_intercept,\n",
    "                   {xp: np.linspace(-4.0, 4.0, 2)[:, np.newaxis]}),\n",
    "          color='black', alpha=0.1)\n",
    " for _ in range(50)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_post = ed.copy(y, {weights: q_weights,\n",
    "                     intercept: q_intercept})\n",
    "# this is equivalent to\n",
    "# y_post = Normal(loc=ed.dot(x, q_weights) + q_intercept,\n",
    "#                 scale=tf.ones(N1))\n",
    "# ed.copy works for us only because Np=N1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error on test data:\")\n",
    "print(ed.evaluate('mean_squared_error', data={x: x_test, y_post: y_test}))\n",
    "\n",
    "print(\"Mean absolute error on test data:\")\n",
    "print(ed.evaluate('mean_absolute_error', data={x: x_test, y_post: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# too much noise!\n",
    "# the model could be more confident.\n",
    "# what is the right amount of noise?\n",
    "# what do we do in these cases?\n",
    "# we put a prior on the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior On Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from edward.models import InverseGamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(0.0, 1.0, 0.001)\n",
    "plt.plot(*sess.run([x, InverseGamma(concentration=5.0, rate=1.0).prob(x)]));  # blue\n",
    "plt.plot(*sess.run([x, InverseGamma(concentration=3.0, rate=1.0).prob(x)]));  # green\n",
    "plt.plot(*sess.run([x, InverseGamma(concentration=1.0, rate=1.0).prob(x)]));  # red\n",
    "plt.axvline(x=noise_true**2);  # blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FORWARD MODEL\n",
    "x = tf.placeholder(tf.float32, [N1, D])\n",
    "weights = Normal(loc=tf.zeros(D), scale=tf.ones(D))\n",
    "intercept = Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "var = InverseGamma(concentration=5.0, rate=1.0)  # noise prior\n",
    "y = Normal(loc=ed.dot(x, weights) + intercept,\n",
    "           scale=tf.ones(N1) * tf.sqrt(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BACKWARD MODEL\n",
    "q_weights = Normal(loc=tf.Variable(tf.random_normal([D])),\n",
    "                   scale=tf.nn.softplus(tf.Variable(tf.random_normal([D]))))\n",
    "q_intercept = Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "                     scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))\n",
    "q_var = InverseGamma(concentration=tf.nn.softplus(tf.Variable(tf.random_normal([]))),\n",
    "                     rate=tf.nn.softplus(tf.Variable(tf.random_normal([]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE\n",
    "inference = ed.KLqp(latent_vars={weights: q_weights,\n",
    "                                 intercept: q_intercept,\n",
    "                                 var: q_var},\n",
    "                    data={x: x_train1,\n",
    "                          y: y_train1})\n",
    "inference.run(n_samples=50, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICISM\n",
    "xp = tf.range(0.0, 1.0, 0.001)\n",
    "plt.plot(*sess.run([xp, q_var.prob(xp)]));\n",
    "plt.axvline(x=noise_true**2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = tf.range(0.0, 4, 0.001)\n",
    "plt.plot(*sess.run([xp, q_weights.prob(xp)]));\n",
    "plt.axvline(x=weights_true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = tf.range(-4, 0, 0.001)\n",
    "plt.plot(*sess.run([xp, q_intercept.prob(xp)]));\n",
    "plt.axvline(x=intercept_true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train1, y_train1, s=20.0);  # blue\n",
    "plt.scatter(x_test, y_test, s=20.0,\n",
    "            color=sns.color_palette().as_hex()[2]);  # red\n",
    "\n",
    "xp = tf.placeholder(tf.float32, [2, D])\n",
    "[plt.plot(np.linspace(-4.0, 4.0, 2),\n",
    "          sess.run(ed.dot(xp, q_weights) + q_intercept,\n",
    "                   {xp: np.linspace(-4.0, 4.0, 2)[:, np.newaxis]}),\n",
    "          color='black', alpha=0.1)\n",
    " for _ in range(50)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_post = ed.copy(y, {weights: q_weights,\n",
    "                     intercept: q_intercept,\n",
    "                     var: q_var})\n",
    "# this is equivalent to\n",
    "# y_post = Normal(loc=ed.dot(x, q_weights) + q_intercept,\n",
    "#                 scale=tf.ones(N1) * tf.sqrt(q_var))\n",
    "# ed.copy works for us only because Np=N1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error on test data:\")\n",
    "print(ed.evaluate('mean_squared_error', data={x: x_test, y_post: y_test}))\n",
    "\n",
    "print(\"Mean absolute error on test data:\")\n",
    "print(ed.evaluate('mean_absolute_error', data={x: x_test, y_post: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use The Posterior for Batch 1 as The Prior for Batch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FORWARD MODEL FOR 2nd BATCH\n",
    "x = tf.placeholder(tf.float32, [N2, D])\n",
    "weights = q_weights\n",
    "intercept = q_intercept\n",
    "var = q_var\n",
    "y = Normal(loc=ed.dot(x, weights) + intercept, scale=tf.ones(N2) * tf.sqrt(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BACKWARD MODEL FOR 2nd BATCH\n",
    "q_weights2 = Normal(loc=tf.Variable(tf.random_normal([D])),\n",
    "                    scale=tf.nn.softplus(tf.Variable(tf.random_normal([D]))))\n",
    "q_intercept2 = Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "                      scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))\n",
    "q_var2 = InverseGamma(concentration=tf.nn.softplus(tf.Variable(tf.random_normal([]))),\n",
    "                      rate=tf.nn.softplus(tf.Variable(tf.random_normal([]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE FOR 2nd BATCH\n",
    "inference = ed.KLqp(latent_vars={weights: q_weights2,\n",
    "                                 intercept: q_intercept2,\n",
    "                                 var: q_var2},\n",
    "                    data={x: x_train2,\n",
    "                          y: y_train2})\n",
    "inference.run(n_samples=50, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICISM FOR 2nd BATCH\n",
    "plt.scatter(np.concatenate((x_train1, x_train2)),\n",
    "            np.concatenate((y_train1, y_train2)), s=20.0);  # blue\n",
    "plt.scatter(x_test, y_test, s=20.0,\n",
    "            color=sns.color_palette().as_hex()[2]);  # red\n",
    "\n",
    "xp = tf.placeholder(tf.float32, [2, D])\n",
    "[plt.plot(np.linspace(-4.0, 4.0, 2),\n",
    "          sess.run(ed.dot(xp, q_weights2) + q_intercept2,\n",
    "                   {xp: np.linspace(-4.0, 4.0, 2)[:, np.newaxis]}),\n",
    "          color='black', alpha=0.1)\n",
    " for _ in range(50)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xp = tf.placeholder(tf.float32, [Np, D])\n",
    "y_post = Normal(loc=ed.dot(xp, q_weights2) + q_intercept2,\n",
    "                scale=tf.ones(Np) * tf.sqrt(q_var2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error on test data:\")\n",
    "print(ed.evaluate('mean_squared_error', data={xp: x_test, y_post: y_test}))\n",
    "\n",
    "print(\"Mean absolute error on test data:\")\n",
    "print(ed.evaluate('mean_absolute_error', data={xp: x_test, y_post: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (PyCon)",
   "language": "python",
   "name": "python2_pycon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
